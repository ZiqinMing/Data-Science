The study aims to draw definitive conclusions about the performance of the XGBoost algorithm in predicting stock prices.

In the XGBoost_Demo.ipynb file, we perform data preprocessing on the tran.csv and val.csv dataset and use the min-max normalization method to process the closing price of the stock data. Its purpose is to scale the numerical data so that it falls into a certain range (usually between 0-1). The converted data can be better processed by some machine learning algorithms. Then in the algorithm implementation stage, we customized an XGBoost model. After fitting the model, we saved the model for subsequent model calls. In the hyperparameter optimization stage of machine learning, it often requires a lot of testing and time to find a relatively best parameter. So we specified several candidate values for the required parameters and used a grid search to determine the optimal solution via RMSE. After selecting the optimal solution, we use MSE, RMSE, MAE, and RÂ² to evaluate our model. After visualizing the predictive model, we used a backtest function to simulate the stock's return to further evaluate our adjusted model. Finally, we selected the model with the highest stock return as the result of this study.

The XGBoost_test_val.ipynb file is our test file, and the same process mentioned above applies only to the val.csv dataset.
